{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sunosa/AI-Agent-Code-Generator/blob/main/embed_tweets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# From HuggingFace dataset to [Qdrant](https://qdrant.tech/) vector database in 12 minutes flat\n",
        "This notebook demonstrates how to transform a HuggingFace dataset into a local Qdrant vector database, using the Sentence Transformers `all-MiniLM-L6-v2` model.\n",
        "\n",
        "For more information on the dataset, which consists of tweets made by American senators, check out the article [Fine-tuning DistilBERT on senator tweets](https://medium.com/@mary.newhauser/fine-tuning-distilbert-on-senator-tweets-a6f2425ca50e).\n",
        "\n",
        "ðŸ’¾ [Dataset](https://huggingface.co/datasets/m-newhauser/senator-tweets)"
      ],
      "metadata": {
        "id": "p30DAVQ9p73n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, change the notebook runtime type to enable GPU usage by clicking the downward-facing arrow in the upper right hand corner of the notebook next to the `RAM` and `Disk` buttons.\n",
        "\n",
        "Click `Change runtime type`  >  select `T4 GPU`  >  click `Save`"
      ],
      "metadata": {
        "id": "-NYwhT3M5Oyz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LUiZ_zcUcxzP"
      },
      "outputs": [],
      "source": [
        "# Install necessary packages\n",
        "!pip install qdrant-client>=1.1.1\n",
        "!pip install -U sentence-transformers==2.2.2\n",
        "!pip install -U datasets==2.16.1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import math\n",
        "import torch\n",
        "from itertools import islice\n",
        "from tqdm import tqdm\n",
        "from qdrant_client import models, QdrantClient\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from datasets import load_dataset, concatenate_datasets"
      ],
      "metadata": {
        "id": "0LvwLV9Cc27y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Record start time\n",
        "start_time = time.time()"
      ],
      "metadata": {
        "id": "ntxw0bDV8xqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine device based on GPU availability\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQTWv82qW54H",
        "outputId": "e5e7e94c-f515-49fb-ef65-0b38c6e108e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load model and dataset"
      ],
      "metadata": {
        "id": "SiSvdTkKtm7N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "dataset = load_dataset(\"m-newhauser/senator-tweets\")\n",
        "\n",
        "# If the embeddings column already exists, remove it (so we can practice generating it!)\n",
        "for split in dataset:\n",
        "    if 'embeddings' in dataset[split].column_names:\n",
        "        dataset[split] = dataset[split].remove_columns('embeddings')\n",
        "\n",
        "# Take a peak at the dataset\n",
        "print(dataset)\n",
        "dataset[\"train\"].to_pandas().head()"
      ],
      "metadata": {
        "id": "lpq00UHDUbXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the desired model\n",
        "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2', device=device)"
      ],
      "metadata": {
        "id": "__OlcWYmP08g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate embeddings for text data"
      ],
      "metadata": {
        "id": "S75hgGKPttZQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create function to generate embeddings (in batches) for a given dataset split\n",
        "def generate_embeddings(split, batch_size=32):\n",
        "    embeddings = []\n",
        "    split_name = [name for name, data_split in dataset.items() if data_split is split][0]\n",
        "\n",
        "    with tqdm(total=len(split), desc=f\"Generating embeddings for {split_name} split\") as pbar:\n",
        "        for i in range(0, len(split), batch_size):\n",
        "            batch_sentences = split['text'][i:i+batch_size]\n",
        "            batch_embeddings = model.encode(batch_sentences)\n",
        "            embeddings.extend(batch_embeddings)\n",
        "            pbar.update(len(batch_sentences))\n",
        "\n",
        "    return embeddings\n",
        "\n",
        "# Generate and append embeddings to the train split\n",
        "train_embeddings = generate_embeddings(dataset['train'])\n",
        "dataset[\"train\"] = dataset[\"train\"].add_column(\"embeddings\", train_embeddings)\n",
        "\n",
        "# Generate and append embeddings to the test split\n",
        "test_embeddings = generate_embeddings(dataset['test'])\n",
        "dataset[\"test\"] = dataset[\"test\"].add_column(\"embeddings\", test_embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "losFcRNwUz3X",
        "outputId": "c8e3b2cb-da35-4021-d6c7-3aeb0f3c5d85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating embeddings for train split: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79754/79754 [06:17<00:00, 211.51it/s]\n",
            "Generating embeddings for test split: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19939/19939 [00:37<00:00, 537.94it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optional: Save the embeddings dataset to the HuggingFace Hub"
      ],
      "metadata": {
        "id": "16KeOlC7z4SS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Log in to the Hub via the CLI\n",
        "# !huggingface-cli login"
      ],
      "metadata": {
        "id": "0O9KZXcov0p8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Push the embeddings dataset (with preserved splits) to the HuggingFace Hub\n",
        "# dataset.push_to_hub(\n",
        "#     repo_id=\"m-newhauser/senator-tweets\", # name of your dataset\n",
        "#     commit_message=\"Add all-MiniLM-L6-v2 embeddings\", # commit message\n",
        "# )"
      ],
      "metadata": {
        "id": "3jyvs1pGuvKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create local Qdrant DB and upsert embeddings"
      ],
      "metadata": {
        "id": "mpfpqAyj0Uy0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine train and test splits into a single dataset\n",
        "combined_dataset = concatenate_datasets([dataset['train'], dataset['test']])"
      ],
      "metadata": {
        "id": "iFqRTSlah1Bb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an in-memory Qdrant instance\n",
        "client = QdrantClient(\":memory:\")\n",
        "\n",
        "# Create a Qdrant collection for the embeddings\n",
        "client.create_collection(\n",
        "    collection_name=\"senator-tweets\",\n",
        "    vectors_config=models.VectorParams(\n",
        "        size=model.get_sentence_embedding_dimension(),\n",
        "        distance=models.Distance.COSINE,\n",
        "    ),\n",
        ")"
      ],
      "metadata": {
        "id": "Kq0YWwZORNwI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create function to upsert embeddings in batches\n",
        "def batched(iterable, n):\n",
        "    iterator = iter(iterable)\n",
        "    while batch := list(islice(iterator, n)):\n",
        "        yield batch"
      ],
      "metadata": {
        "id": "yByu1xgAhcUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define batch size\n",
        "batch_size = 100\n",
        "\n",
        "# Upsert the embeddings in batches\n",
        "for batch in batched(combined_dataset, batch_size):\n",
        "    ids = [point.pop(\"id\") for point in batch]\n",
        "    vectors = [point.pop(\"embeddings\") for point in batch]\n",
        "\n",
        "    client.upsert(\n",
        "        collection_name=\"senator-tweets\",\n",
        "        points=models.Batch(\n",
        "            ids=ids,\n",
        "            vectors=vectors,\n",
        "            payloads=batch,\n",
        "        ),\n",
        "    )"
      ],
      "metadata": {
        "id": "50HMjmYlRrZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Search the database"
      ],
      "metadata": {
        "id": "nG7hIqJ13Gr1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's see what senators are saying about immigration policy\n",
        "hits = client.search(\n",
        "    collection_name=\"senator-tweets\",\n",
        "    query_vector=model.encode(\"Immigration policy\").tolist(),\n",
        "    limit=5\n",
        ")\n",
        "for hit in hits:\n",
        "  print(hit.payload, \"score:\", hit.score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XBFjP05iEiw",
        "outputId": "5fb44151-cd50-44fb-e536-441e6d6b7cdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'date': '2021-06-08 20:50:41', 'username': 'SenatorRomney', 'text': 'Some policies that can realistically stem the illegal immigration crisis: - Completion of the barrier at our southern border - Enact mandatory E-Verify - Require asylum seekers to apply in their home country or the nearest safe location', 'party': 'Republican', 'labels': 0} score: 0.6172380655717898\n",
            "{'date': '2021-11-03 17:56:55', 'username': 'JohnCornyn', 'text': 'Making crisis worse: Biden administration rescinds Trump-era policy limiting migrants at legal ports of entry - CNNPolitics https://t.co/LpSYwdKGER', 'party': 'Republican', 'labels': 0} score: 0.601150868004457\n",
            "{'date': '2021-03-04 17:16:42', 'username': 'SenTedCruz', 'text': 'President Bidens immigration policies are dangerous.', 'party': 'Republican', 'labels': 0} score: 0.5960106315252139\n",
            "{'date': '2021-01-21 01:10:11', 'username': 'SenatorDurbin', 'text': 'With his Executive Orders, President Biden is turning the page on four years of immigration policies that dragged our country backwards. Today, we move forward with a vision that reflects our proud heritage as a nation of immigrants. My full statement: https://t.co/Rwmu2esKnm', 'party': 'Democrat', 'labels': 1} score: 0.5954160128335837\n",
            "{'date': '2021-04-01 21:20:36', 'username': 'SenTomCotton', 'text': 'President Bidens reversal of President Trumps policies caused a surge of illegal migrants who are seeking better jobsnot fleeing harm. My bill would require migrants to apply for protection before making the trek to our southern border. https://t.co/06gbIN96jY', 'party': 'Republican', 'labels': 0} score: 0.5905010397143613\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Most of those tweets are by Republicans... let's see what the Dem's are saying\n",
        "hits = client.search(\n",
        "    collection_name=\"senator-tweets\",\n",
        "    query_vector=model.encode(\"Immigration policy\").tolist(),\n",
        "    query_filter=models.Filter(\n",
        "        must=[\n",
        "            models.FieldCondition(\n",
        "                key=\"party\",\n",
        "                match=models.MatchValue(value=\"Democrat\") # Filter by political party\n",
        "            )\n",
        "        ]\n",
        "    ),\n",
        "    limit=5\n",
        ")\n",
        "for hit in hits:\n",
        "  print(hit.payload, \"score:\", hit.score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8vBQhd7jLhC",
        "outputId": "ee6c6ae7-168b-4ff9-b5bc-66e7edff82ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'date': '2021-01-21 01:10:11', 'username': 'SenatorDurbin', 'text': 'With his Executive Orders, President Biden is turning the page on four years of immigration policies that dragged our country backwards. Today, we move forward with a vision that reflects our proud heritage as a nation of immigrants. My full statement: https://t.co/Rwmu2esKnm', 'party': 'Democrat', 'labels': 1} score: 0.5954159442904414\n",
            "{'date': '2021-05-09 23:00:00', 'username': 'SenatorSinema', 'text': 'Our Bipartisan Border Solutions Act will: - Create regional processing centers along the border - Provide more resources to improve the asylum process - Require @DHSgov to tell communities before releasing migrants https://t.co/e2yAL4TfH4', 'party': 'Democrat', 'labels': 1} score: 0.5691308095316189\n",
            "{'date': '2021-07-10 16:00:02', 'username': 'SenatorSinema', 'text': 'Our Bipartisan Border Solutions Act with @JohnCornyn will help address the migrant crisis by creating regional processing centers to more quickly process migrants while ensuring they are treated fairly and humanely. https://t.co/dJGLpByIbF', 'party': 'Democrat', 'labels': 1} score: 0.5661421280420379\n",
            "{'date': '2021-02-19 02:23:00', 'username': 'ChrisCoons', 'text': 'We can keep families together, manage the border, and protect workers but only when we reform our immigration laws. Our #USCitizenshipAct provides a comprehensive and long-overdue vision to deliver on these priorities. https://t.co/zJTVAKpNBi', 'party': 'Democrat', 'labels': 1} score: 0.5625578529248838\n",
            "{'date': '2021-05-24 20:49:49', 'username': 'SenatorDurbin', 'text': 'The challenge we face now is to establish a fair, sustainable immigration policy which secures our borders and our conscience.', 'party': 'Democrat', 'labels': 1} score: 0.5625173547789559\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Record end time\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate and print the elapsed time\n",
        "elapsed_time = end_time - start_time\n",
        "\n",
        "print(f\"Notebook completed in {int(elapsed_time // 60)} minutes and {math.ceil(elapsed_time % 60)} seconds.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGrZal1nAP0F",
        "outputId": "7b5259f5-bae9-429a-ecd4-f2ca04644759"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Notebook completed in 11 minutes and 35 seconds.\n"
          ]
        }
      ]
    }
  ]
}